{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification of images with a convolutional DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U --no-cache-dir \\\n",
    "#   keras \\\n",
    "#   kaggle \\\n",
    "#   tensorflow-gpu==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "data_dir = '/content/data'\n",
    "output_dir = '/content/output'\n",
    "\n",
    "# avoid future errors caused by missing directories\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c dogs-vs-cats -p /content/data\n",
    "\n",
    "!unzip -n -q /content/data/train.zip -d /content/data\n",
    "!unzip -n -q /content/data/test1.zip -d /content/data\n",
    "\n",
    "original_data_count = len([name for name in os.listdir(os.path.join(data_dir, 'train'))])\n",
    "print(\"Image count: %s\" % original_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I have for this problem is a large collection of images containing either a cat or a dog. The sizes of these images vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%pylab inline\n",
    "\n",
    "img = image.load_img(os.path.join(data_dir, 'train/cat.1.jpg'))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make this a small data problem so I'll seperate the training data into three collections. A training set of 1000. A validation set of 500. And, a test set of 500. Sub directories are added for the two class as I'll be using Keras's ImageDataGenerator to read in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "base_dir = os.path.join(data_dir, 'cats-dogs-small')\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "try:\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "    os.mkdir(train_cats_dir)\n",
    "    for i in range(1000):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(train_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)        \n",
    "    \n",
    "    os.mkdir(train_dogs_dir)\n",
    "    for i in range(1000):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(train_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    for i in range(1000, 1500):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(validation_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(validation_dogs_dir)\n",
    "    for i in range(1000, 1500):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(validation_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(test_cats_dir)\n",
    "    for i in range(1500, 2000):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(test_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(test_dogs_dir)\n",
    "    for i in range(1500, 2000):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(test_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# check image collections are sized correctly\n",
    "print('Train cats: %s' % len(os.listdir(train_cats_dir)))\n",
    "print('Train dogs: %s' % len(os.listdir(train_dogs_dir)))\n",
    "print('Validate cats: %s' % len(os.listdir(validation_cats_dir)))\n",
    "print('Validate dogs: %s' % len(os.listdir(validation_dogs_dir)))\n",
    "print('Test cats: %s' % len(os.listdir(test_cats_dir)))\n",
    "print('Test dogs: %s' % len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in JPEG format really aren't suitable inputs for the model. They need reworked into tensors. Decoding a JPEG into a bitmap gives me a tensor with shape (150, 150, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = test_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in train_generator:\n",
    "    images = x_batch\n",
    "    labels = list(map(lambda x: 'dog' if x == 1.0 else 'cat', y_batch))\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(20):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "std_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "std_model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=1e-4),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "std_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_history = std_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series\n",
    "\n",
    "def plot_loss(history, smooth=False):\n",
    "    loss = Series(data=history['loss'])\n",
    "    val_loss = Series(history['val_loss'])\n",
    "    num_epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    if smooth:\n",
    "        loss = loss.rolling(window=6).mean()\n",
    "        val_loss = val_loss.rolling(window=6).mean()\n",
    "    \n",
    "    plt.plot(num_epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(history, smooth=False):\n",
    "    acc = Series(history['acc'])\n",
    "    val_acc = Series(history['val_acc'])\n",
    "    num_epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    if smooth:\n",
    "        acc = acc.rolling(window=6).mean()\n",
    "        val_acc = val_acc.rolling(window=6).mean()\n",
    "    \n",
    "    plt.plot(num_epochs, acc, 'ro', label='Training accuracy')\n",
    "    plt.plot(num_epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(std_history.history)\n",
    "plot_accuracy(std_history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model has the characteristics of overfitting. Accuracy on the training data increases Linearly towards 100% while accuracy on the validation data stalls before the 10th epoch. Common methods for avoiding overfitting are dropout and weight decay but in this case I will use data augmentation as its well suited to image recognition problems. This technique creates new images by applying transformations to the input tensors while still keeping its recognisable characteristics. The ImageDataGenerator class has the utility to achieve this given a few extra parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                           rotation_range=40,\n",
    "                           width_shift_range=0.2,\n",
    "                           height_shift_range=0.2,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           horizontal_flip=True,\n",
    "                           fill_mode='nearest')\n",
    "\n",
    "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as Img\n",
    "\n",
    "img = Img.load_img(os.path.join(original_data_dir, 'cat.1.jpg'))\n",
    "x = Img.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for batch in augmented_train_datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(Img.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "aug_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "aug_model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=1e-4),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_history = aug_model.fit_generator(\n",
    "    augmented_train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = aug_history.history\n",
    "\n",
    "plot_loss(hist['loss'], hist['val_loss'])\n",
    "plot_accuracy(hist['acc'], hist['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, acc) = aug_model.evaluate_generator(test_generator)\n",
    "\n",
    "print('With data augmentation and dropout the model achieves an accuracy of %f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction of a pre-trained model\n",
    "\n",
    "To achieve a higher accuracy I will leverage a pre-trained model with a convolutional base containing a generic representation of the visual world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.applications import VGG16\n",
    "\n",
    "fe_model_path = os.path.join(output_dir, 'cats-vs-dogs-feat-ext.h5')\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "fe_model = Sequential([\n",
    "    conv_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# must set weight trainability before compilation\n",
    "conv_base.trainable = False\n",
    "\n",
    "fe_model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=2e-5), # decreased learning rate should mean less divergence\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "fe_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "fe_history = fe_model.fit_generator(\n",
    "    augmented_train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n",
    "fe_model.save(fe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(fe_history.history)\n",
    "plot_accuracy(fe_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, acc) = fe_model.evaluate_generator(test_generator, steps=10)\n",
    "print('With feature extraction the model achieves an accuracy of %f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "I can improve the model by unfreezing several layers at the top of the convolutional base  (containing high level representation of features) and re-training them along with the fully connected layers which have learned a representation of the data.\n",
    "\n",
    "Fine-tuning is only possible after the fully connected layer on top of the convolutional base is trained, otherwise the error signal propagating through the network will destroy the representations held in the unfrozen layers. It’s benifitual to unfreeze the top layers of the model as they contain the hight level representations of the classes the pre-trained model. It would be ineffective to unfreeze the lower layers containing low level representations  (such as lines and curves) as these will be relevant to all image classification problems.\n",
    "\n",
    "A very small learning rate prevents the useful representations in the unfrozen layers and the previous trained fully connected layer from being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "tuned_model_path = os.path.join(output_dir, 'cats-vs-dogs-tuned.h5')\n",
    "\n",
    "tuned_model = load_model(fe_model_path)\n",
    "\n",
    "conv_base = tuned_model.get_layer(name='vgg16')\n",
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "frozen_layers = filter(lambda x : 'block5' not in x.name, conv_base.layers)\n",
    "for layer in frozen_layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "tuned_model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=RMSprop(lr=1e-5),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_history = tuned_model.fit_generator(\n",
    "    augmented_train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n",
    "tuned_model.save(tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(tuned_history.history, smooth=True)\n",
    "plot_accuracy(tuned_history.history, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, acc) = tuned_model.evaluate_generator(test_generator, steps=50)\n",
    "print('After fine-tuning the model achieves an accuracy of %f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
