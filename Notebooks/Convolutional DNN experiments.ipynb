{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification of images with a convolutional DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install unzip\n",
    "\n",
    "!pip install -U --no-cache-dir \\\n",
    "  tensorflow==1.12.0 \\\n",
    "  tensorflow-gpu==1.12.0 \\\n",
    "  kaggle \\\n",
    "  pillow==3.4.1 \\\n",
    "  scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle && echo '{\"username\":\"\",\"key\":\"\"}' > ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c dogs-vs-cats -p /content/data\n",
    "\n",
    "!unzip -n -q /content/data/train.zip -d /content/data\n",
    "!unzip -n -q /content/data/test1.zip -d /content/data\n",
    "\n",
    "original_data_count = len([name for name in os.listdir('/content/data/train')])\n",
    "print(\"Image count: %s\" % original_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I have for this problem is a large collection of images containing either a cat or a dog. The sizes of these images vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%pylab inline\n",
    "\n",
    "img = image.load_img('/content/data/train/cat.1.jpg')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make this a small data problem so I'll seperate the training data into three collections. A training set of 1000. A validation set of 500. And, a test set of 500. Sub directories are added for the two class as I'll be using Keras's ImageDataGenerator to read in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base_dir = '/content/data/cats-dogs-small'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "try:\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "    os.mkdir(train_cats_dir)\n",
    "    for i in range(1000):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(train_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)        \n",
    "    \n",
    "    os.mkdir(train_dogs_dir)\n",
    "    for i in range(1000):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(train_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    for i in range(1000, 1500):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(validation_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(validation_dogs_dir)\n",
    "    for i in range(1000, 1500):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(validation_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(test_cats_dir)\n",
    "    for i in range(1500, 2000):\n",
    "        src = os.path.join(original_data_dir, 'cat.%s.jpg') % i\n",
    "        dst = os.path.join(test_cats_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    \n",
    "    os.mkdir(test_dogs_dir)\n",
    "    for i in range(1500, 2000):\n",
    "        src = os.path.join(original_data_dir, 'dog.%s.jpg') % i\n",
    "        dst = os.path.join(test_dogs_dir, '%s.jpg') % i\n",
    "        shutil.copyfile(src, dst)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# check image collections are sized correctly\n",
    "print('Train cats: %s' % len(os.listdir(train_cats_dir)))\n",
    "print('Train dogs: %s' % len(os.listdir(train_dogs_dir)))\n",
    "print('Validate cats: %s' % len(os.listdir(validation_cats_dir)))\n",
    "print('Validate dogs: %s' % len(os.listdir(validation_dogs_dir)))\n",
    "print('Test cats: %s' % len(os.listdir(test_cats_dir)))\n",
    "print('Test dogs: %s' % len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in JPEG format really aren't suitable inputs for the model. They need reworked into tensors. Decoding a JPEG into a bitmap gives me a tensor with shape (150, 150, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = test_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in train_generator:\n",
    "    images = x_batch\n",
    "    labels = list(map(lambda x: 'dog' if x == 1.0 else 'cat', y_batch))\n",
    "    break\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=1e-4),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "num_epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(num_epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(num_epochs, acc, 'ro', label='Training accurcy')\n",
    "plt.plot(num_epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model has the characteristics of overfitting. Accuracy on the training data increases Linearly towards 100% while accuracy on the validation data stalls before the 10th epoch. Common methods for avoiding overfitting are dropout and weight decay but in this case I will use data augmentation as its well suited to image recognition problems. This technique creates new images by applying transformations to the input tensors while still keeping its recognisable characteristics. The ImageDataGenerator class has the utility to achieve this given a few extra parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                           rotation_range=40,\n",
    "                           width_shift_range=0.2,\n",
    "                           height_shift_range=0.2,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           horizontal_flip=True,\n",
    "                           fill_mode='nearest')\n",
    "\n",
    "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img('/content/data/train/cat.1.jpg')\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "i = 0\n",
    "for batch in augmented_train_datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=1e-4),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    augmented_train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "num_epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(num_epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Loss with data augmentation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_epochs, acc, 'ro', label='Training accuracy')\n",
    "plt.plot(num_epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Accuracy with data augmentation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
